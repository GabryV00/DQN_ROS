{"time": [22.0, 145.0, 20.0, 20.0, 29.0, 35.0, 24.0, 52.0, 17.0, 42.0, 13.0, 52.0, 97.0, 32.0, 28.0, 21.0, 23.0, 30.0, 29.0, 34.0, 35.0, 14.0, 19.0, 20.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0], "rewards": [90, 1320, 70, 70, 160, 220, 110, 390, 40, 290, 0, 390, 840, 190, 150, 80, 100, 170, 160, 210, 220, 10, 60, 70, 60, 70, 80, 90, 100, 110], "model": "DQN(\n  (fc1): Linear(in_features=120, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=256, bias=True)\n  (fc4): Linear(in_features=256, out_features=128, bias=True)\n  (fc5): Linear(in_features=128, out_features=64, bias=True)\n  (fc6): Linear(in_features=64, out_features=32, bias=True)\n  (head): Linear(in_features=32, out_features=3, bias=True)\n)", "gamma": 0.999, "epsilon_start": 0.9, "epsilon_end": 0.05, "epsilon_decay": 200, "n_episodes": 30, "batch_size": 128, "optimizer": "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.01\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)", "learning_rate": 0.01}