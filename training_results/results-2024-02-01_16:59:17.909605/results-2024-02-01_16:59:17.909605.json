{"time": [57.0, 54.0, 98.0, 91.0, 39.0, 41.0, 72.0, 69.0, 299.0, 177.0, 195.0, 20.0, 19.0, 20.0, 20.0, 20.0, 19.0, 22.0, 19.0, 19.0, 20.0, 20.0, 20.0, 21.0, 20.0, 20.0, 20.0, 22.0, 49.0, 66.0], "rewards": [790, 790, 1625, 1575, 625, 665, 1315, 1210, 5735, 3340, 3625, 20, 0, 20, 20, 20, 0, 75, 0, 0, 5, 20, 20, 40, 5, 35, 5, 60, 615, 1180], "model": "DQN(\n  (fc1): Linear(in_features=120, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=256, bias=True)\n  (fc4): Linear(in_features=256, out_features=128, bias=True)\n  (fc5): Linear(in_features=128, out_features=64, bias=True)\n  (fc6): Linear(in_features=64, out_features=32, bias=True)\n  (head): Linear(in_features=32, out_features=3, bias=True)\n)", "gamma": 0.999, "epsilon_start": 0.9, "epsilon_end": 0.05, "epsilon_decay": 200, "n_episodes": 30, "batch_size": 128, "optimizer": "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.01\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)", "learning_rate": 0.01}