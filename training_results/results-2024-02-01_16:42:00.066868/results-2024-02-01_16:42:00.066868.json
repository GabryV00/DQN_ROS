{"time": [43.0, 40.0, 27.0, 65.0, 34.0, 36.0, 28.0, 38.0, 33.0, 79.0, 41.0, 39.0, 28.0, 30.0, 37.0, 25.0, 74.0, 20.0, 14.0, 59.0, 62.0, 68.0, 16.0, 21.0, 14.0, 41.0, 66.0, 41.0, 22.0, 21.0], "rewards": [21, 18, 5, 47, 12, 10, 6, 16, 15, 61, 15, 17, 10, 16, 15, 11, 112, 6, 8, 101, 124, 110, 2, 15, 0, 91, 128, 79, 16, 15], "model": "DQN(\n  (fc1): Linear(in_features=120, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=256, bias=True)\n  (fc4): Linear(in_features=256, out_features=128, bias=True)\n  (fc5): Linear(in_features=128, out_features=64, bias=True)\n  (fc6): Linear(in_features=64, out_features=32, bias=True)\n  (head): Linear(in_features=32, out_features=3, bias=True)\n)", "gamma": 0.999, "epsilon_start": 0.9, "epsilon_end": 0.25, "epsilon_decay": 5, "n_episodes": 30, "batch_size": 512, "optimizer": "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.01\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)", "learning_rate": 0.01}