{"time": [116.0, 22.0, 29.0, 55.0, 21.0, 46.0, 42.0, 21.0, 52.0, 35.0, 25.0, 41.0, 96.0, 73.0, 80.0, 166.0, 174.0, 361.0, 38.0, 33.0, 38.0, 44.0, 30.0, 13.0, 22.0, 26.0, 11.0, 11.0, 21.0, 20.0], "rewards": [4980, 640, 990, 1900, 170, 1510, 1220, 170, 1690, 900, 640, 1650, 4400, 3250, 3600, 7960, 8360, 17470, 1470, 830, 1020, 1290, 680, 160, 250, 540, 60, 0, 260, 150], "model": "DQN(\n  (fc1): Linear(in_features=120, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=256, bias=True)\n  (fc4): Linear(in_features=256, out_features=128, bias=True)\n  (fc5): Linear(in_features=128, out_features=64, bias=True)\n  (fc6): Linear(in_features=64, out_features=32, bias=True)\n  (head): Linear(in_features=32, out_features=3, bias=True)\n)", "gamma": 0.999, "epsilon_start": 0.9, "epsilon_end": 0.05, "epsilon_decay": 200, "n_episodes": 30, "batch_size": 128, "optimizer": "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.01\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)", "learning_rate": 0.01}